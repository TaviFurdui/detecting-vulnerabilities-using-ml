# -*- coding: utf-8 -*-
"""CombinedEDA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1G5rplZ6N3Bjk76LjV5TOF6rrpKSQG5pP
"""

from google.colab import drive
import zipfile
import os

drive.mount('/content/drive')

import pandas as pd

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)
pd.set_option('display.max_colwidth', None)

df_juliet = pd.read_csv('/content/drive/My Drive/juliet.csv')

df_natural = pd.read_csv('/content/drive/My Drive/real-world.csv')

df_true = df_juliet[df_juliet['is_vuln'] == True].sample(n=30000, random_state=42)
df_false = df_juliet[df_juliet['is_vuln'] == False].sample(n=30000, random_state=42)

df_test_juliet = pd.concat([df_true, df_false]).reset_index(drop=True)

df_test_juliet_subset = df_test_juliet[['function_code_generic', 'is_vuln']].copy()
df_test_juliet_subset.columns = ['func', 'target']

df_test_natural_subset = df_natural[['func', 'target']].copy()

df_test = pd.concat([df_test_juliet_subset, df_test_natural_subset], ignore_index=True)

print(df_test.shape)

import re

def remove_comments_from_func_column(df, column_name='func'):
    def clean_code(code):
        if not isinstance(code, str):
            return ''
        code = re.sub(r'//.*?$|#.*?$', '', code, flags=re.MULTILINE)
        code = re.sub(r'/\*.*?\*/', '', code, flags=re.DOTALL)
        code = re.sub(r'[^\w\s]', ' ', code)
        code = re.sub(r'\s+', ' ', code)
        return code.strip().lower()

    df_cleaned = df.copy()
    df_cleaned[column_name] = df_cleaned[column_name].apply(clean_code)
    return df_cleaned

df_test_juliet_subset_cleaned = remove_comments_from_func_column(df_test_juliet_subset)
df_test_natural_subset_cleaned = remove_comments_from_func_column(df_test_natural_subset)
df_test_cleaned = remove_comments_from_func_column(df_test)

print(df_test_cleaned['func'][0])

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from collections import Counter

text = ' '.join(df_test_juliet_subset_cleaned['func'].dropna().astype(str))
words = [word for word in text.split() if len(word) > 2 and not word.isnumeric()]
word_counts = Counter(words)
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

text = ' '.join(df_test_natural_subset_cleaned['func'].dropna().astype(str))
words = [word for word in text.split() if len(word) > 2 and not word.isnumeric()]
word_counts = Counter(words)
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

text = ' '.join(df_test_cleaned['func'].dropna().astype(str))
words = [word for word in text.split() if len(word) > 2 and not word.isnumeric()]
word_counts = Counter(words)
wordcloud = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(word_counts)

plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

import pandas as pd
import re

def extract_code_features(df, column='func'):
    def compute_features(code):
        if not isinstance(code, str):
            return {
                'num_lines': 0,
                'average_line_length': 0,
                'cyclomatic_complexity': 1,
                'num_chars': 0,
                'num_tokens': 0,
                'average_token_length': 0
            }

        lines = code.strip().split('\n')
        num_lines = len(lines)
        line_lengths = [len(line.strip()) for line in lines]
        average_line_length = sum(line_lengths) / num_lines if num_lines > 0 else 0
        num_chars = sum(line_lengths)

        tokens = re.findall(r'\b\w+\b', code)
        num_tokens = len(tokens)
        average_token_length = num_chars / num_tokens if num_tokens > 0 else 0

        complexity_keywords = ['if', 'for', 'while', 'case', '&&', '||', '?', 'else if']
        complexity = 1 + sum(len(re.findall(r'\b' + re.escape(k) + r'\b', code)) for k in complexity_keywords)

        return {
            'num_lines': num_lines,
            'average_line_length': average_line_length,
            'cyclomatic_complexity': complexity,
            'num_chars': num_chars,
            'num_tokens': num_tokens,
            'average_token_length': average_token_length
        }

    feature_df = df.copy()
    features = feature_df[column].apply(compute_features).apply(pd.Series)
    return pd.concat([feature_df, features], axis=1)

df_test_features = extract_code_features(df_test)
df_natural_features = extract_code_features(df_test_natural_subset)
df_juliet_features = extract_code_features(df_test_juliet_subset)

print("df_test Features:")
print(df_test_features[['func', 'num_lines', 'average_line_length', 'cyclomatic_complexity', 'num_chars', 'num_tokens', 'average_token_length']].head())

print("\ndf_natural_subset Features:")
print(df_natural_features[['func', 'num_lines', 'average_line_length', 'cyclomatic_complexity', 'num_chars', 'num_tokens', 'average_token_length']].head())

print("\ndf_juliet_subset Features:")
print(df_juliet_features[['func', 'num_lines', 'average_line_length', 'cyclomatic_complexity', 'num_chars', 'num_tokens', 'average_token_length']].head())

def calculate_global_statistics(df_features):
    stats = df_features[['num_lines', 'average_line_length', 'cyclomatic_complexity',
                         'num_chars', 'num_tokens', 'average_token_length']].agg(
        ['min', 'max', 'mean', 'std'])
    return stats

# Calculate global stats for each dataset
df_test_stats = calculate_global_statistics(df_test_features)
df_natural_stats = calculate_global_statistics(df_natural_features)
df_juliet_stats = calculate_global_statistics(df_juliet_features)

# Display the results in a tabular format
print("Global Stats for df_test:")
print(df_test_stats)

print("\nGlobal Stats for df_natural_subset:")
print(df_natural_stats)

print("\nGlobal Stats for df_juliet_subset:")
print(df_juliet_stats)

import seaborn as sns

df_test["function_length"] = df_test["func"].apply(lambda x: len(str(x)))

plt.figure(figsize=(8, 5))
sns.histplot(df_test, x="function_length", hue="target", bins=30, kde=True, multiple="stack")

plt.xlabel("Function Length (characters)")
plt.ylabel("Count")
plt.title("Distribution of Function Lengths by Vulnerability Label")

plt.show()

df_test_juliet_subset["function_length"] = df_test_juliet_subset["func"].apply(lambda x: len(str(x)))

plt.figure(figsize=(8, 5))
sns.histplot(df_test_juliet_subset, x="function_length", hue="target", bins=30, kde=True, multiple="stack")

plt.xlabel("Function Length (characters)")
plt.ylabel("Count")
plt.title("Distribution of Function Lengths by Vulnerability Label")

plt.show()

df_test_natural_subset["function_length"] = df_test_natural_subset["func"].apply(lambda x: len(str(x)))

plt.figure(figsize=(8, 5))
sns.histplot(df_test_natural_subset, x="function_length", hue="target", bins=30, kde=True, multiple="stack")

plt.xlabel("Function Length (characters)")
plt.ylabel("Count")
plt.title("Distribution of Function Lengths by Vulnerability Label")

plt.show()

sns.pairplot(df_test_features[['num_lines', 'average_line_length', 'cyclomatic_complexity', 'target']], hue='target', palette="Set1")
plt.suptitle("Pairplot of Features by Vulnerability Label", y=1.02)
plt.show()